###### Guardians of the galaxy
# The unacknowledged legislators of the online world 
![image](images/20190615_BKD001_0.jpg) 
> print-edition iconPrint edition | Books and arts | Jun 15th 2019 
Behind the Screen. By Sarah Roberts.Yale University Press; 280 pages; $30 and £20. 
THEY ARE paid to spend their days watching filth: beheadings and chemical-weapons attacks, racist insults and neo-Nazi cartoons, teenagers encouraging each other to starve, people having sex with animals or with ex-lovers against whom they want revenge. When batches of images leap onto their screens, they must instantly sort them into categories, such as violence, hate speech and “dare” videos, in which people offer to do whatever a stranger asks. If the material violates the platform’s explicit policies (nudity, sensationalistic gore), they take it down. If it contains suicide threats or evidence of a crime, they alert law-enforcement authorities. If it is a borderline case (violence with possible journalistic content, say), they mark it for review. Some earn $15 an hour, some a piece-work rate of a few cents per item, sorting anywhere from 400 to 2,000 a day. 
With soldierly bravado, they insist the job does not upset them. “I handle stress pretty well,” says one of the social-media content moderators interviewed by Sarah Roberts in “Behind the Screen”—before admitting to gaining weight and developing a drink problem. They avoid discussing their work with friends or family, but it intrudes anyway. War-zone footage, child sex-abuse and threats of self-harm are especially hard to repress. “My girlfriend and I were fooling around on the couch or something and she made a joke about a horse,” says another moderator. “And I’d seen horse porn earlier in the day and I just shut down.” 
Those who work directly for the big American internet platforms may boast about it to their friends, but they are mainly on short-term contracts with little kudos or chance of promotion. At a huge Silicon Valley firm that Ms Roberts calls MegaTech, the content moderators were barred from using the climbing wall. Even further down the hierarchy are third-party contractors in India and the Philippines, who handle material for corporate websites, dating sites and online retailers, as well as for the big platforms. Whether in San Francisco or Manila, their task is fundamentally the same. These are the rubbish-pickers of the internet; to most of the world, they are all but invisible. 
An estimated 150,000 people work in content moderation worldwide. Ms Roberts’s book is one of just a few about them. Much of her research was conducted early this decade; for recent developments, she is obliged to refer to articles by journalists such as Adrian Chen of Wired. But in some ways little has changed. A short documentary Mr Chen made in 2017 about moderators in India suggests the job was largely the same as it was in California in 2012. 
One reason content moderation is hard to investigate is that social-media companies prefer not to talk about it. The platforms have never been comfortable with their role as gatekeepers. Like much of Silicon Valley, their culture reflects the libertarian optimism of the internet’s pioneers, which Ms Roberts terms “an origin myth of unfettered possibility for democratic free expression”. Early cyberspace utopians thought censorship would soon be obsolete: the internet would treat it as a broken node and route around it. (The Great Firewall of China had not yet been erected.) Until recently, strategists at giant social-media firms seemed to imagine they were still running the sorts of self-policing communities which existed on text-only messaging boards in the 1990s, and which survive today on forums like 4chan and Reddit. 
The platforms also have less rarefied reasons to keep content moderation out of the public eye. America’s law on online content, the Communications Decency Act of 1996, lets internet companies restrict it as they see fit, and holds them largely immune from liability for third-party material on their websites. A fear that legislators might deem the firms’ methods biased or inadequate—and decide to regulate them—makes executives circumspect in both what they do and how they talk about it. The big platforms and their contractors routinely require moderators to sign non-disclosure agreements. 
Since the American presidential election of 2016 and the Brexit referendum, controversies over fake news, hate speech and online harassment have forced internet companies to bring content moderation into the light—up to a point. Facebook says it now has 30,000 people working on safety and security worldwide, of whom half are moderators (many of them employed by outside contractors). Twitter has beefed up its moderation staff; it now boasts about the number of accounts it suspends, sometimes millions per month. A new German law requires internet sites to delete material that breaks hate-speech laws within 24 hours of a complaint. Last week YouTube began taking down thousands of channels that violated policies against racism, sexism and religious bigotry. It has also been criticised for algorithms (now amended) that routed family videos to viewers who expressed an interest in child porn. 
These efforts have exposed the platforms to just the sort of criticisms they are least comfortable with. Alt-right YouTubers whose channels are taken down because of racism complain they are being censored by the liberal establishment. Some history channels were initially knocked out too, because they displayed racist material in order to critique it (they have since largely been restored). Still, when targets of suspensions complain, they are usually met by a boilerplate statement that their content violated company policies, with no explanation of what those policies are or exactly what the violation was. 
As Ms Roberts shows, the opacity is ingrained. Social-media sites have often been reluctant to tell malefactors precisely what they did wrong. Beside the political risks, they fear that would let provocateurs flirt with the edges of prohibitions, and furnish endless fodder for challenges to their decisions. A report in February by the Verge, a news site, found that a Facebook subcontractor’s training regime required moderators to learn a decision-tree of rules, then justify which one led to a take-down. Even so, individual instances often involve subjective judgments, which are almost never explained to users. 
For years, tech activists have called for more transparency about these boundaries. But some say that simply revealing the rules is insufficient, because formal criteria can never capture the irreducible moral and political decisions moderators make. Ms Roberts’s subjects already faced such dilemmas in 2011, when MegaTech decided that gruesome images from the Arab spring constituted news (and so could stay), but equally grim ones from gang conflicts in Central America had to go. 
Others think the focus on what may be published misses the bigger question of which posts get amplified—by being shared, liked or “ratioed” (the current term for a wave of negative comments). Last week Carlos Maza, a reporter for Vox.com, pilloried YouTube for refusing to take down videos by Steven Crowder, a conservative YouTuber who had mocked him using homophobic slurs. As well as complaining about the slurs themselves, Mr Maza said he had been subjected to online harassment by some of Mr Crowder’s many followers. This raises the difficult question of whether platforms should impose stricter rules on influential personalities. 
A different approach was suggested last year by Tarleton Gillespie, a consultant, in his book “Custodians of the Internet”. Part of the problem, he says, is that both users and companies have got it wrong: content moderation is not a peripheral inconvenience, but “in many ways, the commodity that platforms offer”. Increasingly, these sites are where people conduct their lives, and the task of keeping them within acceptable bounds of discourse, and excluding the unconscionable, may be the most important thing the firms do. It is too demanding for harried box-tickers. 
Facebook has recently raised moderators’ pay; YouTube has limited their exposure to disturbing videos to four hours a day. But in general, as Ms Roberts chronicles, moderators are treated as low-skilled labour. She is particularly good at depicting how the strange international network of content moderation mirrors the class divides of other globalised industries. Just as it dumps some of its nastiest refuse in poor countries, the West leaves it to them to sort much of the internet’s yuckiest trash. ◼ 
<<<<<<< HEAD
-- 
 单词注释:
1.guardian['gɑ:diәn]:n. 看守者, 监护人, 保护人 a. 保护的 
2.galaxy['gælәksi]:n. 银河, 星系, 一群(显赫的人物) [电] 银河系 
3.unacknowledged[.ʌnәk'nɒlidʒd]:a. 未被承认的, 未被公认的, 未答复的 
4.legislator['ledʒisleitә]:n. 立法者, 立法官, 立法委员 [法] 立法者, 立法机关成员, 立法委员 
5.online[]:[计] 联机 
6.Jun[dʒʌn]:六月 
7.Sarah['sєәrә]:n. 萨拉(<<圣经>>故事人物) 
8.beheading[]:[法] 斩首 
9.racist['reisist]:n. 种族主义者 [法] 种族主义的, 种族歧视 
10.batch[bætʃ]:n. 一次所烘的面包, 一次所制之量, 一组, 批, 成批, 分批 v. 成批, 分批处理 [计] 一批 
11.nudity['nju:diti]:n. 裸露, 裸露物, 裸体像 
12.sensationalistic[]:a. sensationalist的变形 
13.gore[gɒ:]:n. 流出的血, 淤血, 三角形布 vt. 把...剪成楔形三角布, 缝以补裆, 刺伤, 抵 
14.suicide['sjuisaid]:n. 自杀, 自杀者 v. 自杀 a. 自杀的 
15.borderline['bɒ:dәlain]:n. 边界, 界线 a. 边界的 
16.journalistic[,dʒ\\: nә'listik]:a. 新闻业的, 新闻工作者的, 报刊特有的, 新闻工作的 
17.soldierly['sәuldʒәli]:a. 军人的, 像军人的, 适于军人的 
18.bravado[brә'vɑ:dәu]:n. 虚张声势 
19.moderator['mɒdәreitә]:n. 主席, 会议主持人, 仲裁人 [计] 筛选人 
20.Robert['rɔbәt]:[法] 警察 
21.intrude[in'tru:d]:vi. 闯入, 侵入 vt. 强加于 
22.footage['futidʒ]:n. 英尺长度, 英板尺, (影片的)连续镜头 
23.repress[ri'pres]:vt. 镇压, 抑制, 压制 vi. 压制 
24.girlfriend[]:n. 女朋友 
25.couch[kautʃ]:n. 长沙发, 睡椅, 卧榻 vt. 横躺, 表达 vi. 躺下, 蹲伏 
26.porn[pɔ:n]:n. 色情描写, 黄色书刊, 色情画, 色情照片, 色情文学 
27.kudo['kju:dәu]:n. 奖赏, 光荣, 荣誉 
28.promotion[prәu'mәuʃәn]:n. 晋级, 创建, 增进 [经] 推广, 推销, 促进 
29.silicon['silikәn]:n. 硅 [化] 硅Si 
30.megatech[]:[网络] 杨金顺；科技学院 
31.hierarchy['haiәrɑ:ki]:n. 等级制度, 僧侣统治, 等级体系 [计] 分级结构; 分层结构; 新闻组, 新闻组分层 
32.contractor['kɒntræktә]:n. 立契约的人, 承包商 [化] 承包者; 承包工厂 
33.Philippine['filipi:n]:a. 菲律宾(群岛)的, 菲律宾人的 
34.corporate['kɒ:pәrit]:a. 社团的, 合伙的, 公司的 [经] 团体的, 法人的, 社团的 
35.retailer['ri:teilә]:n. 零售商人, 传播的人 [经] 零售商 
36.san[sɑ:n]:abbr. 存储区域网（Storage Area Networking） 
37.francisco[fræn'siskәu]:n. 弗朗西斯科（男子名, 等于Francis） 
38.Manila[mә'nilә]:n. 马尼拉 
39.fundamentally[fʌndә'mentәli]:adv. 基础, 首要, 主要, 十分重要, 基本, 根本, 原始, 基频, 基音, 基谐波 
40.moderation[.mɒdә'reiʃәn]:n. 缓和, 适度, 温和 [化] 慢化 
41.adrian['eidriәn]:n. 艾德里安（男子名）；艾德里安市（美国密歇根州东南部城市） 
42.chen[]:n. 陈 
43.documentary[.dɒkju'mentәri]:n. 记录片 a. 文件的 
44.California[.kæli'fɒ:njә]:n. 加利福尼亚 
45.gatekeeper['geitki:pә]:n. 看门人 
46.libertarian[.libә'tєәriәn]:n. 自由意志主义支持者, 行动自由者 a. 自由意志主义支持者的, 主张个人思想的 
47.optimism['ɒptimizm]:n. 乐观主义, 乐观, 乐天 [医] 乐观主义, 乐观 
48.myth[miθ]:n. 神话, 虚构的事, 虚构的人 
49.unfetter[.ʌn'fetә]:vt. 给...解开脚链, 释放, 使自由 [法] 除去...脚镣, 释放 
50.cyberspace[]:[计] 空间, 网控空间 
51.Utopian[ju:'tәupiәn]:a. 乌托邦的, 空想社会主义的 n. 理想社会主义者 
52.censorship['sensәʃip]:n. 检查制度 [医] 督察, 监察 
53.node[nәud]:n. 节, 结节, 瘤 [计] 节点; 结点 
54.firewall[]:[计] 放火墙, 隔离 
55.strategist['strætidʒist]:n. 战略家 
56.forum['fɒ:rәm]:n. 论坛, 公开讨论的广场, 法庭, 讨论会 [法] 讨论会, 专题讨论, 公共论坛 
57.reddit[]:n. （新闻网站名）红迪网 
58.les[lei]:abbr. 发射脱离系统（Launch Escape System） 
59.rarefy['rєәrifai]:vt. 使稀少, 使稀薄, 使纯化, 精炼 vi. 变稀少, 变稀薄 
60.decency['di:sәnsi]:n. 得体, 礼貌, 正派 [法] 正当, 正派, 合乎礼仪 
61.immune[i'mju:n]:a. 免疫的, 免除的, 不受影响的 n. 免疫者 
62.liability[laiә'biliti]:n. 责任, 债务, 倾向 [经] 责任, 义务, 负债 
63.deem[di:m]:v. 认为, 相信 
64.bias['baiәs]:n. 偏见, 斜纹 a. 偏斜的 adv. 偏斜 vt. 使有偏见 [计] 偏流; 偏压; 偏磁; 偏离 
65.circumspect['sә:kәmspekt]:a. 细心的, 慎重的 
66.routinely[]:adv. 日常, 乏味, 常规, 例行 
67.presidential[.prezi'denʃәl]:a. 总统制的, 总统的, 首长的, 统辖的 [法] 总统的, 议长的, 总经理的 
68.Brexit[]:[网络] 英国退出欧盟 
69.referendum[.refә'rendәm]:n. （就重大政治或社会问题进行的）全民公决，全民投票 
70.controversy['kɒntrәvә:si]:n. 论争, 辩论, 论战, 争论 [法] 论战, 争论, 争吵 
71.fake[feik]:n. 假货, 欺骗, 诡计 a. 假的 vt. 假造, 仿造 vi. 伪装 
72.harassment['hærәsmәnt]:n. 困扰, 烦扰, 烦恼 [法] 折磨, 骚扰, 侵扰 
73.facebook[]:n. 脸谱网 
74.twitter['twitә]:n. 啁啾, 唧唧喳喳声 vi. 啭, 啁啾, 颤抖 vt. 嘁嘁喳喳地讲, 抖动 
75.youtube[]:n. 视频网站（可以让用户免费上传、观赏、分享视频短片的热门视频共享网站） 
76.racism['reisizm]:n. 种族主义, 种族偏见 [法] 种族主义, 种族歧视, 种族歧视主张 
77.sexism['seksizm]:n. 性别歧视, 歧视女性 
78.bigotry['bigәtri]:n. 盲从, 偏见, 偏执的行为(或态度) 
79.criticise['kritisaiz]:v. 批评, 吹毛求疵, 非难 
80.algorithm['ælgәriðm]:n. 算法 [计] 算法 
81.amend[ә'mend]:vt. 修改, 改善, 改良 vi. 改过自新 
82.rout[raut]:n. 溃败, 大败, 乌合之众, 盛大晚会 vt. 使溃败, 使败逃, 打垮, 用鼻拱, 挖起, 搜, 唤起 vi. 用鼻拱地, 搜 
83.YouTubers[]:[网络] 素人翻唱歌手 
84.censor['sensә]:n. 检查员 vt. 检查, 审查, 删改 
85.initially[i'niʃәli]:adv. 最初, 开头 
86.critique[kri'ti:k]:n. 评论文章, 评论 
87.boilerplate['bɔilәpleit]:n. 样板文件 
88.violation[.vaiә'leiʃәn]:n. 违反, 违背, 妨碍 [法] 违犯, 违背, 违反 
89.opacity[әu'pæsiti]:n. 不透明, 电波不透过, 不透明体 [医] 浑浊, 不透明, 不透光, 不透明区, 浊斑 
90.ingrain[in'grein]:vt. 给原纱染色, 使根深蒂固 a. 原纱染色的, 根深蒂固的 n. 原纱染色, 固有品质 
91.malefactor['mælifæktә]:n. 罪人, 犯人, 坏人 [法] 罪犯, 作恶者 
92.precisely[pri'saisli]:adv. 精确地, 明确地, 刻板地, 拘泥地, 正好, 恰恰, 对, 正是如此, 确实如此, 不错 
93.provocateur[]:[法] 挑衅者, 挑拨者, 煽动者 
94.flirt[flә:t]:n. 卖弄风骚的人, 急动, 急扔 vt. 忽然弹出, 轻快摆动, 挥动 vi. 调情, 玩弄, 摆动, 轻率地对待 
95.prohibition[.prәuhi'biʃәn]:n. 禁令, 禁止 
96.fodder['fɒdә]:n. 饲料, 草料, 素材, 弹药 vt. 喂 
97.verge[vә:dʒ]:n. 边缘, 边界, 起始点 vi. 处在边缘, 接近, 下沉, 趋向 
98.regime[rei'ʒi:m]:n. 政权, 当权期间, 政体, 社会制度, 体制, 情态 [医] 制度, 生活制度 
99.judgment['dʒʌdʒmәnt]:n. 裁判, 宣告, 判决书 [医] 判断 
100.tech[tek]:n. 技术学院或学校 
101.activist['æktivist]:n. 激进主义分子 
102.transparency[træns'pærәnsi]:n. 透明, 透明度, 透过性, 透明物, 清晰 [计] 透明性; 透明 
103.irreducible[.iri'dju:sәbl]:a. 不能复归的, 不能削减的, 不可约的 [医] 不能复位的, 不能还原的 
104.gruesome['gru:sәm]:a. 可怕的, 令人毛骨悚然的, 阴森的 
105.constitute[kәn'stitjut]:vt. 构成, 组成, 任命 [建] 构造, 组成 
106.equally['i:kwәli]:adv. 相等地, 同样地, 平等地 
107.grim[grim]:a. 冷酷的, 坚强的, 残忍的, 可怕的, 讨厌的 
108.ratioed[]:[网络] 比例 
109.carlo[]:n. 卡洛（男子名） 
110.maza[]:[医] 胎盘 
111.pillory['pilәri]:n. 颈手枷, 笑柄, 示众 vt. 上颈手枷, 使惹人嘲笑, 使受众辱, 将...示众 
112.steven['sti:vn]:n. 史蒂文（男子名） 
113.crowder[]:n. 沟渠扫污机 
114.youtuber[]:油管人（频繁使用视频分享网站YouTube的用户，特别是自己制作视频并且出镜的人们） 
115.mock[mɒk]:n. 嘲笑, 戏弄, 模仿 a. 假的, 伪造的, 模拟的 adv. 虚伪地 vt. 嘲弄, 模仿, 使失望, 欺骗, 挫败 vi. 嘲弄 
116.homophobic[,hɔmə'fəubik]:a. 害怕同性恋的 
117.slur[slә:]:n. 连音符, 诽谤, 玷污, 印刷模糊 vt. 草率地看过, 忽略, 含糊地念 vi. 模糊不清 
118.follower['fɒlәuә]:n. 从者, 属下, 追补者 [电] 随动机 
119.tarleton[]: [人名] [英格兰人姓氏] 塔尔顿住所名称，来源于古诺斯语人名Porvaldr+古英语，含义是“圈用地，居留地”(enclosure,settlement); [人名] [英格兰人姓氏] 塔尔顿住所名称，来源于古英语，含义是“棘丛+圈用地，居留地”(thorn bush+enclosure,settlement); [地名] [英国] 塔尔顿 
120.Gillespie[[gi'lespi]]:n. 吉莱斯皮（姓） 
121.custodian[kʌ'stәudjәn]:n. 管理人, 保管人, 监护人 [经] 保管人, 管理人 
122.peripheral[pә'rifәrәl]:a. 周边的, 周围的, 圆周的, 无关紧要的, 肤浅的 [医] 外周的, 周围的, 末梢的 
123.inconvenience[.inkәn'vi:njәns]:n. 不便, 困难 vt. 使感不便, 使感困难 
124.commodity[kә'mɒditi]:n. 农产品, 商品, 有用的物品 [经] 商品, 货物, 日用品 
125.discourse['diskɒ:s]:n. 谈话, 演讲 vi. 谈话, 讲述 
126.unconscionable[.ʌn'kɒnʃәnәbl]:a. 不受良心支配的, 不合理的, 过度的 
127.harry['hæri]:vt. 掠夺, 使苦恼, 强使前行, 折磨, 骚扰 
128.chronicle['krɒnikl]:n. 年代记, 记录, 编年史 vt. 把...载入编年史 
129.depict[di'pikt]:vt. 描述, 描写 
130.globalise[]:使全球化（英式英语） 
131.yuckiest[]:adj. 〈非正式〉脏的；丑的；令人讨厌的 [网络] 怎么翻译及发音 
132.trash[træʃ]:n. 垃圾, 废物 vt. 丢弃 
=======
>>>>>>> 50f1fbac684ef65c788c2c3b1cb359dd2a904378
