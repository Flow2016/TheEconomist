###### Battle algorithm
# Artificial intelligence is changing every aspect of war 
![image](images/20190907_STP001_0.jpg) 
> print-edition iconPrint edition | Science and technology | Sep 7th 2019 
AS THE NAVY plane swooped low over the jungle, it dropped a bundle of devices into the canopy below. Some were microphones, listening for guerrilla footsteps or truck ignitions. Others were seismic detectors, attuned to minute vibrations in the ground. Strangest of all were the olfactory sensors, sniffing out ammonia in human urine. Tens of thousands of these electronic organs beamed their data to drones and on to computers. In minutes, warplanes would be on their way to carpet-bomb the algorithmically-ordained grid square. Operation Igloo White was the future of war—in 1970. 
America’s effort to cut the Ho Chi Minh trail running from Laos into Vietnam was not a success. It cost around $1bn a year (about $7.3bn in today’s dollars)—$100,000 ($730,000 today) for every truck destroyed—and did not stop infiltration. But the allure of semi-automated war never faded. The idea of collecting data from sensors, processing them with algorithms fuelled by ever-more processing power and acting on the output more quickly than the enemy lies at the heart of military thinking across the world’s biggest powers. And today that is being supercharged by new developments in artificial intelligence (AI). 
AI is “poised to change the character of the future battlefield”, declared America’s Department of Defence in its first AI strategy document, in February. A Joint Artificial Intelligence Centre (JAIC) was launched in the Pentagon in summer 2018, and a National Security Commission on Artificial Intelligence met for the first time in March. The Pentagon’s budget for 2020 has lavished almost $1bn on AI and over four times as much on unmanned and autonomous capabilities that rely on it. 
A similar flurry of activity is under way in China, which wants to lead the world in AI by 2030 (by what measure is unclear), and in Russia, where President Vladimir Putin famously predicted that “whoever becomes the leader in this sphere will become the ruler of the world”. But the paradox is that AI might at once penetrate and thicken the fog of war, allowing it to be waged with a speed and complexity that renders it essentially opaque to humans. 
AI is a broad and blurry term, covering a range of techniques from rule-following systems, pioneered in the 1950s, to modern probability-based machine learning, in which computers teach themselves to carry out tasks. Deep learning—a particularly fashionable and potent approach to machine learning, involving many layers of brain-inspired neural networks—has proved highly adept at tasks as diverse as translation, object recognition and game playing (see chart). Michael Horowitz of the University of Pennsylvania compares AI to the internal combustion engine or electricity—an enabling technology with myriad applications. He divides its military applications into three sorts. One is to allow machines to act without human supervision. Another is to process and interpret large volumes of data. A third is aiding, or even conducting, the command and control of war. 
![image](images/20190907_STC991.png) 
Start on the battlefield. The appeal of autonomy is obvious—robots are cheaper, hardier and more expendable than humans. But a machine capable of wandering the battlefield, let alone spilling blood on it, must be intelligent enough to carry that burden—an unintelligent drone will not survive for long in a battle; worse still, an unintelligent gun-toting robot is a war crime waiting to happen. So AI is required to endow machines with the requisite skills. Those include simple ones, like perception and navigation, and higher-order skills, like co-ordination with other agents. 
Intelligent machines that combine these abilities can do things that individual humans cannot. “Already, an AI system can outperform an experienced military pilot in simulated air-to-air combat,” notes Kenneth Payne of King’s College London. In February, the Defence Advanced Research Projects Agency (DARPA), the Pentagon’s blue-sky-thinking branch, conducted the latest test of a six-strong drone swarm capable of collaborating in a “high-threat” environment, even when cut off from human contact. 
For all that, most such systems embody intelligence that is narrow and brittle—good at one task in a well-defined environment, but liable to fail badly in unfamiliar settings. So existing autonomous weapons are comprised of either loitering missiles that smash into radars or quick-firing guns that defend ships and bases. Useful, but not revolutionary—and neither requires the fancy machine-learning techniques pioneered in recent years. 
It would be a mistake to think that AI is useful only for battlefield drudgery. Robots, killer or otherwise, must act on what they see. But for many military platforms, like spy planes and satellites, the point is to beam back raw data that might be turned into useful intelligence. There is now more of that than ever before—in 2011 alone, the most recent year for which there are data, America’s 11,000-or-so drones sent back over 327,000 hours (37 years) of footage. 
Most of that has lain unwatched. Luckily, the second major application for AI in the armed forces will be in processing data. In lab-based tests, algorithms surpassed human performance in image classification by 2015 and nearly doubled their performance in a tougher task, object segmentation, which involves picking out multiple objects from single images, between 2015 and 2018, according to Stanford University’s annual index of AI progress. Computer vision is far from perfect and can be exploited in ways that would not fool a human observer. In one study, altering 0.04% of the pixels in an image of a panda—imperceptible to humans—caused the system to see a gibbon instead. 
Those weaknesses notwithstanding, by February 2017 the Pentagon itself concluded that deep-learning algorithms “can perform at near-human levels”. So it established the “Algorithmic Warfare” team, known as Project Maven, which uses deep learning and other techniques to identify objects and suspicious actions, initially in footage from the war against Islamic State and now more widely. The aim is to produce “actionable” intelligence—the sort that often ends with bombs falling or special forces kicking in doors. 
An insider with knowledge of Project Maven says that the benefits to analysts—in terms of time savings and new insights—remain marginal for now. Wide-angle cameras that can see across entire cities throw up large numbers of false positives, for instance. “But the nature of these systems is highly iterative,” he says. Progress is rapid and Project Maven is just the tip of the iceberg. 
Earth-i, a British company, can apply machine-learning algorithms from a range of satellites to identify different variants of military aircraft across dozens of bases with over 98% accuracy (see main picture), according to Sean Corbett, a retired air vice-marshal in the Royal Air Force (RAF) who now works for the firm. “The clever bit”, he says, “is then developing methods to automatically identify what is normal and what is not normal.” By watching bases over time, the software can distinguish routine deployments from irregular movements, alerting analysts to significant changes. 
Algorithms, of course, are omnivorous and can be fed any sort of data, not just images. “Bulk data combined with modern analytics make the modern world transparent,” noted Sir Alex Younger, the head of MI6, Britain’s spy agency, in December. In 2012 leaked documents from the NSA, America’s signals-intelligence agency, described a programme (reassuringly called Skynet), which applied machine learning to Pakistani mobile-phone data in order to pick out individuals who might be couriers for terrorist groups. Who, for instance, had travelled from Lahore to the border town of Peshawar in the past month—and turned off or swapped their handset more often than usual? “It’s beginning to shift intelligence from the old world, where commanders asked a question and intelligence agencies used collection assets to find the answer, to a world where answers are in...the cloud,” says Sir Richard Barrons, a retired general who commanded Britain’s joint forces until 2016. 
Indeed, the data in question need not always come from an enemy. JAIC’s first project was neither a weapon nor a spying tool, but a collaboration with special forces to predict engine failures in their Black Hawk helicopters. The first version of the algorithm was delivered in April. Air-force tests on command-and-control planes and transporters showed that such predictive maintenance could reduce unscheduled work by almost a third, which might allow big cuts in the $78bn that the Pentagon currently spends on maintenance. 
The point of processing information, of course, is to act on it. And the third way AI will change warfare is by seeping into military decision-making from the lowly platoon to national headquarters. Northern Arrow, a tool built by UNIQAI, an Israeli AI firm, is one of many products on the market that helps commanders plan missions by crunching large volumes of data on variables such as enemy positions, weapon ranges, terrain and weather—a process that would normally take 12 to 24 hours for soldiers the old-fashioned way by poring over maps and charts. It is fed with data from books and manuals—say, on tank speeds at different elevations—and also from interviews with experienced commanders. The algorithm then serves up options to harried decision-makers, along with an explanation of why each was chosen. 
These “expert system” platforms, such as Northern Arrow and America’s similar CADET software, can work far quicker than human minds—two minutes for CADET compared with 16 person-hours for humans, in one test—but they tend to employ rule-following techniques that are algorithmically straightforward. By historical standards this would be considered AI, but most use deterministic methods, which means that the same inputs will always produce the same outputs. This would be familiar to the soldiers who used the outputs of ENIAC, the world’s first electronic general-purpose computer, which generated artillery firing tables in 1945. 
In the real world, randomness often gets in the way of making precise predictions, so many modern AI systems combine rule-following with added randomness as a stepping stone to more complex planning. DARPA’s Real-time Adversarial Intelligence and Decision-making (RAID) software aims to predict the goals, movements and even the possible emotions of enemy forces five hours into the future. The system relies on a type of game theory that shrinks down problems into smaller games, reducing the computational power required to solve them. 
In early tests between 2004 and 2008, RAID performed with greater accuracy and speed than human planners. In simulated two-hour battles in Baghdad, human teams were pitted against either RAID or other humans; they could tell them apart less than half the time. The retired colonels drafted to simulate Iraqi insurgents “got so scared” of the software, notes Boris Stilman, one of its designers, that “they stopped talking to each other and used hand signals instead”. RAID is now being developed for army use. 
![image](images/20190907_stp002.jpg) 
The latest deep-learning systems can be the most enigmatic of all. In March 2016, AlphaGo, a deep-learning algorithm built by DeepMind, beat one of the world’s best players in Go, an ancient Chinese strategy game. In the process it played several highly creative moves that confounded experts. The very next month, China’s Academy of Military Science held a workshop on the implications of the match. “For Chinese military strategists, among the lessons learned from AlphaGo’s victories was the fact that an AI could create tactics and stratagems superior to those of a human player in a game that can be compared to a war-game,” wrote Elsa Kania, an expert on Chinese military innovation. 
In December 2018 another of DeepMind’s programs, AlphaStar, trounced one of the world’s strongest players in StarCraft II, a video game played in real-time, rather than turn-by-turn, with information hidden from players and with many more degrees of freedom (potential moves) than Go. Many officers hope that such game-playing aptitude might eventually translate into a flair for inventive and artful manoeuvres of the sort celebrated in military history. Michael Brown, director of the Defence Innovation Unit, a Pentagon body tasked with tapping commercial technology, says that AI-enabled “strategic reasoning” is one of his organisation’s priorities. 
But if algorithms that surpass human creativity also elude human understanding, they raise problems of law, ethics and trust. The laws of war require a series of judgments about concepts such as proportionality (between civilian harm and military advantage) and necessity. Software that cannot explain why a target was chosen probably cannot abide by those laws. Even if it can, humans might mistrust a decision aid that could outwardly resemble a Magic 8-Ball. 
“What do we do when AI is applied to military strategy and has calculated the probabilistic inferences of multiple interactions many moves beyond that which we can consider,” asks wing-commander Keith Dear, an RAF intelligence officer, “and recommends a course of action that we don’t understand?” He gives the example of an AI that might propose funding an opera in Baku in response to a Russian military incursion in Moldova—a surreal manoeuvre liable to baffle one’s own forces, let alone the enemy. Yet it might result from the AI grasping a political chain of events that would not be immediately perceptible to commanders. 
Even so, he predicts that humans will accept the trade-off between inscrutability and efficiency. “Even with the limitations of today’s technology, an AI might support, if not take over, decision-making in real-world warfighting” by using a “massive near-real-time simulation”. 
That is not as far-fetched as it sounds. Sir Richard Barrons points out that Britain’s defence ministry is already purchasing a technology demonstrator for a cloud-based virtual replication of a complex operating environment—known as a single synthetic environment—essentially a military version of the software that powers large-scale online video games such as “Fortnite”. It is built by Improbable, a gaming company, and CAE, known for its flight simulators, using open standards, so everything from secret intelligence to real-time weather data can be plugged in. “It will revolutionise how command and control is done,” says Sir Richard, as long as there are plentiful data, networks to move it and cloud computing to process it. That would allow a “single synthetic command tool from the national security council down to the tactical commander”. 
Western governments insist that humans will be “on the loop”, supervising things. But even many of their own officers are not convinced. “It seems likely humans will be increasingly both out of the loop and off the team in decision-making from tactical to strategic,” says Commander Dear. The expectation that combat will speed up “beyond the capabilities of human cognition” recurs in Chinese writing, too, says Ms Kania. The result would not only be autonomous weapons, but an automated battlefield. At the outset of a war, interconnected AI systems would pick out targets, from missile launchers to aircraft-carriers, and choreograph rapid and precise strikes to destroy them in the most efficient order. 
The wider consequences of that remain unclear. The prospect of accurate and rapid strikes “could erode stability by increasing the perceived risk of surprise attack”, writes Zachary Davis in a recent paper for the Lawrence Livermore National Laboratory. But AI might equally help defenders parry such blows, by identifying the telltale signs of an impending strike. Or, like America’s sensor-scattering spree in the Vietnamese jungle in the 1960s, such schemes could wind up as expensive and ill-conceived failures. Yet no power wants to risk falling behind its rivals. And here, politics, not just technology, may have an impact. 
The Pentagon’s spending on AI is a fraction of the $20bn-30bn that was spent by large technology firms in 2016. Although many American companies are happy to take defence dollars—Amazon and Microsoft are nearing a $10bn cloud-computing contract with the Pentagon—others are more skittish. In June 2018 Google said it would allow its $9m contract for work on Project Maven to lapse this year, after 4,000 employees protested the company’s involvement in “warfare technology”. 
In China, on the other hand, firms can be easily pressed into the service of the state and privacy laws are a minor encumbrance. “If data is the fuel of AI, then China may have a structural advantage over the rest of the world,” warned Robert Work, a former US deputy secretary of defence, in June. Whether civilian data can fuel military algorithms is not clear, but the question plays on the minds of military leaders. JAIC director General Jack Shanahan expressed his concerns on August 30th: “What I don’t want to see is a future where our potential adversaries have a fully AI-enabled force and we do not.” ■ 
<<<<<<< HEAD
-- 
 单词注释:
1.algorithm['ælgәriðm]:n. 算法 [计] 算法 
2.Sep[]:九月 
3.swoop[swu:p]:n. 俯冲, 攫取 vt. 抓取 vi. 猛扑, 突然袭击 
4.canopy['kænәpi]:n. 天篷, 遮篷, 苍穹 vt. 用天蓬遮盖 
5.guerrilla[gә'rilә]:n. 游击队 
6.ignition[ig'niʃәn]:n. 点火, 点燃 [化] 点火; 着火 
7.seismic['saizmik]:a. 地震的 
8.detector[di'tektә]:n. 发现者, 检验器, 检波器 [计] 检波器; 检测器 
9.attune[ә'tju:n]:vt. 为乐器调音, 使协调, 使合拍 
10.olfactory[ɒl'fæktәri]:a. 嗅觉的, 味道的 n. 嗅觉器官, 嗅神经 
11.sensor['sensә]:n. 传感器 [计] 检测器 
12.ammonia[ә'mәunjә]:n. 氨水, 阿摩尼亚 [化] 氨 
13.urine['juәrin]:n. 小便, 尿 [医] 尿 
14.tens[]:十位 
15.datum['deitәm]:n. 论据, 材料, 资料, 已知数 [医] 材料, 资料, 论据 
16.drone[drәun]:n. 雄蜂, 懒惰者, 嗡嗡的声音, 无人驾驶飞机(或船) vi. 嗡嗡作声, 混日子 vt. 低沉地说 
17.warplane['wɒ:plein]:n. 军用飞机 
18.grid[grid]:n. 格子, 栅格 [计] 网格 
19.igloo['iglu:]:n. 圆顶建筑 
20.HO[hәu]:interj. 嗬(表示惊讶或引人注意) [医] 钬(67号元素) 
21.chi[kai, ki:]:n. 希腊语的第22个字母 [医] 卡, χ(希腊文的第二十二个字母) 
22.Minh[]:n. (Minh)人名；(老、柬)明 
23.lao[lau, 'lɑ:әu]:n. 老挝语；老挝人 
24.Vietnam[.vjet'næm]:n. 越南 
25.infiltration[.infil'treiʃәn]:n. 渗入, 渗透, 渗透物 [化] 渗滤; 渗入过滤; 渗透; 渗入 
26.allure[ә'luә]:vt. 引诱, 吸引 n. 魅力, 诱惑力 
27.quickly['kwikli]:adv. 很快地 
28.supercharge['sju:pәtʃɑ:dʒ]:vt. 对...增压, 使超负荷, 使过度, 使过分 [化] 增压器 
29.AI[ai]:[计] 附加信息, 人工智能 [化] 人工智能 
30.poise[pɒiz]:n. 平衡, 均衡, 姿势, 镇静, 安静, 砝码 vt. 使平衡, 使悬着, 保持...姿势 vi. 平衡, 悬着, 准备好 
31.battlefield['bætlfi:ld]:n. 战场, 沙场 
32.JAIC[]:联合空军情报中心 
33.pentagon['pentәgәn]:n. 五角形, 五边形 [经] 五角平台 
34.lavish['læviʃ]:a. 大方的, 丰富的, 浪费的 vt. 浪费, 滥用, 慷慨给予 
35.unman[.ʌn'mæn]:vt. 使失去男子气概, 使怯懦, 使气馁 
36.capability[.keipә'biliti]:n. 能力, 性能, 约束力 [化] 能力 
37.flurry['flә:ri]:n. 疾风, 飓风, 慌张 vt. 使恐慌, 使激动 vi. 慌张 
38.unclear[.ʌn'kliә]:a. 不易了解的, 不清楚的, 含混的 
39.Vladimir[vlɑ'dimɪr]:n. 弗拉基米尔（古罗斯弗拉基米尔-苏兹达里公国的古都） 
40.putin['putin]:n. 普京（人名） 
41.famously['feimәsli]:adv. 极好地, 非常令人满意地 
42.paradox['pærәdɒks]:n. 似非而是的论点, 自相矛盾的话, 悖论, 怪人怪事 [化] 佯谬 
43.thicken['θikәn]:vi. 变浓, 变厚, 变得模糊, 变为复杂 vt. 使变厚, 加强, 使模糊 
44.complexity[kәm'pleksiti]:n. 复杂, 复杂性, 复杂的事物 
45.essentially[i'senʃәli]:adv. 本质上, 本来 
46.opaque[әu'peik]:n. 不透明物 a. 不透明的, 不传热的, 不传导的, 阴暗的 [计] 白底 
47.blurry['blә:ri]:a. 模糊的, 不清楚的, 污脏的 
48.potent['pәutnt]:a. 有力的, 有说服力的, 有效的 [医] 有力的, 有性交能力的 
49.neural['njuәrәl]:a. 神经的, 神经系统的, 神经中枢的, 背的 [医] 神经的 
50.adept[ә'dept]:a. 熟练的, 老练的, 巧妙的 n. 能手, 内行 
51.michael['maikl]:n. 迈克尔（男子名） 
52.Horowitz[]:霍罗威茨 
53.Pennsylvania[.pensil'veinjә]:n. 宾夕法尼亚 
54.combustion[kәm'bʌstʃәn]:n. 燃烧, 骚动 [化] 燃烧 
55.myriad['miriәd]:n. 无数, 无数的人(或物) a. 无数的, 种种的 
56.supervision[.sju:pә'viʒәn]:n. 监督, 管理 [经] 监督, 管理 
57.autonomy[ɒ:'tɒnәmi]:n. 自治, 自治权 [医] 自主性 
58.hardy['hɑ:di]:a. 难的, 艰苦的, 坚硬的, 勇敢的 adv. 努力地, 辛苦地, 坚硬地 
59.expendable[iks'pendәbl]:a. 可消费的, 消耗性的, 可牺牲的, 值得消耗的, 可消耗的 n. 消耗物, 可牺牲的人, 可牺牲的物 
60.unintelligent['ʌnin'telidʒәnt]:a. 缺乏才智的, 无知的, 愚蠢的 [计] 非智能 
61.endow[in'dau]:vt. 捐赠, 捐助, 赋予 [法] 赠送财产给, 分给寡妇一份遗产, 授与 
62.requisite['rekwizit]:n. 必需品, 要素, 必要物品 a. 必要的, 需要的 
63.perception[pә'sepʃәn]:n. 知觉, 感觉, 领悟力, 获取 [医] 知觉 
64.cannot['kænɒt]:aux. 无法, 不能 
65.outperform[.autpә'fɔ:m]:vt. 胜过；做得比……好 
66.simulate['simjuleit]:vt. 模拟, 假装, 模仿 [法] 伪装的, 模拟的; 假装的, 伪装的, 冒充 
67.combat['kɒmbæt]:n. 争斗, 战斗 vi. 战斗, 争斗 vt. 与...战斗, 与...斗争 
68.kenneth[]:n. 肯尼思（男子名）；[古]英俊的领导者 
69.payne[pein]:n. 佩恩（姓氏）；佩恩（美国剧作家, 演员） 
70.DARPA[]:[计] 美国国防部高级研究计划局 
71.embody[im'bɒdi]:vt. 具体表达, 使具体化 [经] 合并, 具体化, 具体表现 
72.unfamiliar[.ʌnfә'miljә]:a. 不熟悉的 
73.loiter['lɒitә]:v. 闲荡, 虚度, 徘徊 
74.drudgery['drʌdʒәri]:n. 苦差事, 苦工 
75.killer['kilә]:n. (非正式)杀人者, 屠杀者, 猛兽, 致死(疾病), 杀手, 止痛药, 限制器, 瞄准器 [计] 删除程序; 断路器 
76.footage['futidʒ]:n. 英尺长度, 英板尺, (影片的)连续镜头 
77.unwatched['ʌn'wɔtʃt]:[计] 自动的, 无人控制的 
78.luckily['lʌkili]:adv. 幸运地, 幸亏, 侥幸 
79.surpass[sә'pɑ:s]:vt. 超越, 凌驾, 胜过 
80.segmentation[.segmәn'teiʃәn]:n. 分割, 割断, 细胞分裂 [计] 分段; 分割; 段式调度; 分段法 
81.stanford['stænfәd]:n. 斯坦福（姓氏, 男子名）；斯坦福大学（美国一所大学） 
82.pixel['piksәl]:n. 像素 [计] 象素 
83.gibbon['gibәn]:n. 长臂猿 [医] 长臂猿 
84.notwithstanding[.nɒtwiθ'stændiŋ]:adv. 虽然, 尽管 prep. 尽管 conj. 虽然 
85.algorithmic[]:[计] 算法的 
86.warfare['wɒ:fєә]:n. 战争, 战斗, 交战, 斗争, 竞争 [法] 战事, 作战, 交战 
87.maven['meivin]:n. 内行, 专家 
88.initially[i'niʃәli]:adv. 最初, 开头 
89.Islamic[iz'læmik]:a. 伊斯兰教的, 穆斯林的 
90.actionable['ækʃәnәbl]:a. 可提起诉讼的 [经] 能起诉的 
91.insider['in'saidә]:n. 内部的人, 权威人士, 知道内情的人 [经] 熟悉内情者 
92.marginal['mɑ:dʒinәl]:a. 边缘的, 最低限度的, 有旁注的 [医] 缘的 
93.iterative['itәrәtiv]:a. 反复的, 絮叨的 n. 反复体 
94.iceberg['aisbә:g]:n. 冰山, 冷冰冰的人 
95.variant['vєәriәnt]:n. 变体, 异体 a. 不同的, 有差别的 [计] 变体型 
96.sean[ʃɔ:n]:n. 肖恩（男子名） 
97.Corbett[]:科比特（人名） 科比特（地名） 
98.raf[]:abbr. 英国皇家空军（Royal Air Force） 
99.deployment[]:[计] 展开 
100.analyst['ænәlist]:n. 分析者, 精神分析学家 [化] 分析员; 化验员 
101.omnivorous[ɒm'nivәrәs]:a. 无所不吃的, 杂食的, 什么都喜欢的 
102.analytic[.ænә'litik]:a. 分析的, 善于分析的, 解析的 [医] 分析的 
103.Alex[]:[计] 开放网络文件系统 
104.nsa[]:abbr. 美国国家安全局（National Security Agency）；美国国家标准协会（National Standards Association） 
105.reassuringly[ˌri:ə'ʃʊərɪŋlɪ]:adv. 安慰地, 鼓励地 
106.skynet[]:n. 天网（卫星）；天网防火墙 
107.Pakistani[.pɑ:ki'stɑ:ni]:a. 巴基斯坦的 n. 巴基斯坦人 
108.courier['kuriә]:n. 送快信的人, 伴游服务员 [法] 信使, 送急件者 
109.terrorist['terәrist]:n. 恐怖分子 [法] 恐怖份子, 恐怖主义 
110.lahore[lә'hɔ:]:n. 拉合尔（巴基斯坦城市） 
111.Peshawar[pә'ʃɔ:ә]:白沙瓦[巴基斯坦北部城市] 
112.handset['hændset]:n. 电话听筒 
113.asset['æset]:n. 资产, 有益的东西 
114.inthe[]:[网络] 在；身体部位；他在 
115.richard['ritʃәd]:n. 理查德（男子名） 
116.Barron[]:n. 巴伦周刊（美国专业财经周刊）；巴伦（男子名） 
117.alway['ɔ:lwei]:adv. 永远；总是（等于always） 
118.collaboration[kә.læbә'ræʃәn]:n. 合作, 勾结 [法] 通敌卖国者, 奸细 
119.transporter[træns'pɒ:tә]:n. 输送人, 运输机 [化] 运输船; 运输机 
120.predictive[pri'diktiv]:a. 预言性的, 成为前兆的 
121.unscheduled[ʌn'ʃedju:ld]:[计] 不定期的 
122.currently['kʌrәntli]:adv. 现在, 当前, 一般, 普通 [计] 当前 
123.warfare['wɒ:fєә]:n. 战争, 战斗, 交战, 斗争, 竞争 [法] 战事, 作战, 交战 
124.seep[si:p]:vi. 渗出, 渗流, 漏 n. 小泉, 水陆两用吉普车 
125.lowly['lәuli]:a. 地位低的, 卑下的, 谦卑的 adv. 位置低下的, 低声地, 谦逊地 
126.platoon[plә'tu:n]:n. 排, 一组, 一群人 
127.headquarter[,hed'kwɔ:tә]:vt. 将...的总部设在 
128.Israeli[iz'reili]:a. 以色列的, 以色列人(语)的 n. 以色列人 
129.crunch[krʌntʃ]:v. 嘎吱嘎吱的咬嚼, 压碎, 嘎吱嘎吱地踏过 n. 咬碎, 咬碎声 
130.terrain['terein]:n. 地带, 地区, 地形, 领域, 范围 
131.pore[pɒ:]:n. 毛孔, 小孔, 气孔 vi. 专心阅读, 细想, 钻研, 沉思, 注视 vt. 使注视得 
132.harry['hæri]:vt. 掠夺, 使苦恼, 强使前行, 折磨, 骚扰 
133.cadet[kә'det]:n. 军官学校学生 [法] 军校学生 
134.algorithmically[æl'ɡɒrɪθmɪklɪ]: [计] 在算法上 
135.deterministic[di.tә:mi'nistik]:a. 决定论的, 命运注定论的 
136.eniac['i: niæk]:abbr. 电子数字积分计算机, ENIAC计算机（Electronic Numerical Integrator And Calculator） 
137.artillery[ɑ:'tilәri]:n. 火炮, 炮兵, 炮术 [机] 火炮, 炮兵 
138.randomness[]:[计] 随机性 
139.prediction[pri'dikʃәn]:n. 预言, 预报 [化] 预测 
140.adversarial[,ædvә'seәriәl]:a. 敌手的,对手的,对抗(性)的 
141.computational[.kɒmpju'teiʃәnәl]:a. 计算的 
142.planner['plænә]:n. 计划者, 设计者, 安排者 [机] 刨床机 
143.Baghdad['bægdæd]:n. 巴格达 
144.les[lei]:abbr. 发射脱离系统（Launch Escape System） 
145.Iraqi[i'rɑ:ki]:n. 伊拉克人, 伊拉克阿拉伯语 a. 伊拉克的, 伊拉克人的 
146.insurgent[in'sә:dʒәnt]:a. 谋叛的, 起义的, 澎湃的 n. 起义者, 叛乱者 
147.boris['bɔris]:n. 鲍里斯（男子名） 
148.designer[di'zainә]:n. 设计者, 谋划者, 制图者 [计] 设计员 
149.enigmatic[.enig'mætik]:a. 费解的, 谜一般的, 高深莫测的 
150.DeepMind[]:n. 深刻的见解 [网络] 心灵深处；初恋汽水；深层思想 
151.confound[kәn'faund]:vt. 使混淆, 使狼狈, 挫败 
152.strategist['strætidʒist]:n. 战略家 
153.tactic['tæktik]:n. 一项战术, 一条策略 a. 战术的, 顺序的, 排列的 
154.stratagem['strætidʒәm]:n. 策略, 计谋 
155.elsa['elsә]:n. 埃尔莎（女子名, 等于Elizabeth） 
156.kania[]:[网络] 卡尼亚 
157.innovation[.inәu'veiʃәn]:n. 改革, 创新 [法] 创新, 改革, 刷新 
158.alphastar[]:[网络] 阿跌；乐思化学的沉银技术 
159.trounce[trauns]:vt. 痛打, 严惩 
160.starcraft['stɑ:krɑ:ft. -kræft]:n. 占星学 
161.ii[]:abbr. 微光（Image Intensification） 
162.aptitude['æptitju:d]:n. 资质, 才能, 自然倾向 [医] 资质, 才能 
163.flair[fleә]:n. 鉴别力, 才能, 天资, 资质, 眼光 
164.inventive[in'ventiv]:a. 善于创造的, 发明的 
165.artful['ɑ:tful]:a. 巧妙的, 狡猾的 
166.manoeuvre[mә'nu:vә]:n. 调遣, 演习, 策略 vi. 调动, 演习, 用策略 vt. 调动, 操纵 
167.innovation[.inәu'veiʃәn]:n. 改革, 创新 [法] 创新, 改革, 刷新 
168.creativity[.kri:ei'tiviti]:n. 创造力, 创造性 
169.elude[i'lu:d]:vt. 逃避, 规避, 把...难倒 
170.ethic['eθik]:n. 道德规范, 伦理 
171.sery[]:n. (Sery)人名；(俄)谢雷；(科特)塞里 
172.judgment['dʒʌdʒmәnt]:n. 裁判, 宣告, 判决书 [医] 判断 
173.proportionality[prә,pɔ:ʃә'næliti]:n. 比例性, 相称, 均衡性 [机] 比例, 均整 
174.abide[ә'baid]:vi. 停留, 遵守, 居留, 继续下去 vt. 忍受, 经受, 屈从于 
175.mistrust[.mis'trʌst]:n. 不信任, 疑惑 v. 不信任, 疑惑 
176.outwardly['ajtwәdli]:adv. 表面上, 在外, 外表上 
177.probabilistic[,prɔbәbi'listik]:[计] 概率性的 
178.inference['infәrәns]:n. 推论 [法] 推论, 推理, 推断 
179.keith[ki:θ]:n. 基思（男子名） 
180.Baku[bɑ:'ku:]:n. 巴库 
181.incursion[in'kә:ʃәn]:n. 侵入, 侵略, 奇袭 
182.surreal[sә'riәl]:a. 超现实主义的；离奇的；不真实的 
183.baffle['bæfl]:vt. 困惑, 为难, 使挫折 vi. 徒作挣扎 n. 迷惑, 挡板 
184.perceptible[pә'septibl]:a. 可察觉的, 能感觉得到的, 看得见的 
185.inscrutability[in.skru:tә'biliti]:n. 不可预测, 不可解, 不可思议 
186.warfighting['wɔː(r).faɪtɪŋ]:n. 作战；(导弹)弹头战 [网络] 战斗 
187.simulation[.simju'leiʃәn]:n. 模拟, 假冒物, 模仿 [计] 模拟 
188.demonstrator['demәnstreitә]:n. 论证者, 证明者, 指示者, 示威者 [医] 示教者 
189.replication[.repli'keiʃәn]:n. 回答, 反响, 复制, 第二次答辩, 折转, 弯回 [化] 复制 
190.online[]:[计] 联机 
191.improbable[im'prɒbәbl]:a. 不大可能的, 不象发生的, 荒谬可笑的 [法] 未必会的, 不大可能发生的, 未必确实的 
192.CAE[]:[计] 计算机辅助教育, 计算机辅助工程, 计算机辅助实验, 计算机辅助估算 
193.simulator['simjuleitә]:n. 模拟器, 假装者 [计] 模拟器 
194.revolutionise[,revә'lju:ʃənaiz]:vt. 使革命化, 彻底改革, 彻底改变 
195.computing[kәm'pju:tiŋ]:[计] 计算 
196.tactical['tæktikl]:a. 战术的, 用兵上的, 策略的 
197.supervise['sju:pәvaiz]:v. 监督, 管理, 指导 
198.cognition[kɒg'niʃәn]:n. 认识, 认识力, 认识的结果 [医] 认识, 识别 
199.recur[ri'kә:]:vi. 复发, 回到, 重现, 再来, 诉诸, 采用, 循环 
200.automate['ɔ:tәmeit]:vt.vi. (使)自动化 [计] 自动化 
201.interconnect[.intәkә'nekt]:vt. 使互相连接 
202.launcher['lɒ:ntʃә]:n. 发射者, 发射台 
203.choreograph['kɒriәgrɑ:f]:v. 设计舞蹈动作 
204.erode[i'rәud]:vt. 腐蚀, 侵蚀 vi. 受腐蚀 
205.zachary['zækәri]:n. 圣扎迦利（等于Zacharias, Saint）；扎卡里（男子名） 
206.davis['deivis]:n. 戴维斯（男子名） 
207.lawrence['lɔrәns]:n. 劳伦斯（男子名） 
208.Livermore['livə,mɔ:]:n. 利弗莫尔（美国加利福尼亚州西部城市） 
209.equally['i:kwәli]:adv. 相等地, 同样地, 平等地 
210.defender[di'fendә]:n. 防卫者, 防护者, 辩护者 [法] 辩护人, 保护人 
211.parry['pæri]:vt. 挡开, 回避, 闪避的回答 n. 挡开, 回避, 闪避的回答 
212.telltale['telteil]:n. 搬弄是非者, 迹象, 指示器 a. 搬弄是非的, 泄露秘密的, 报警的 
213.impend[im'pend]:vi. 迫近, 威胁, 悬挂 
214.spree[spri:]:n. 戏耍, 喧闹, 宴会, 狂饮 vi. 狂欢, 狂饮 
215.vietnamese['vjetnә'mi:z]:n. 越南人；越南语 
216.politic['pɒlitik]:a. 精明的, 明智的, 策略的 
217.Microsoft[]:n. (美国)微软公司 [电] 微软公司 
218.skittish['skitiʃ]:a. 易惊的, 轻佻的, 三心二意的, 不可靠的, 羞怯的, 活泼的, 爱蹦跳的, 活跃的 
219.google[]:谷歌；搜索引擎技术；谷歌公司 
220.lapse[læps]:n. 过失, 流逝, 失效 vi. 犯错, 堕落, 减退, 消失, 流逝 vt. 使失效 
221.involvement[in'vɔlvmәnt]:n. 卷入, 牵连, 包含, 困窘 [经] 财政困难, 经济上的困窘 
222.privacy['praivәsi]:n. 隐私, 隐居, 秘密 [计] 个人保密权 
223.encumbrance[in'kʌmbrәns]:n. 阻碍, 妨害物, 累赘 [法] 累赘, 负担, 财产留置权 
224.Robert['rɔbәt]:[法] 警察 
225.jack[dʒæk]:n. 插座, 千斤顶, 男人 vt. 抬起, 提醒, 扛举, 增加, 提高, 放弃 a. 雄的 [计] 插座 
226.Shanahan[]:n. (Shanahan)人名；(英)沙纳汉 
227.adversary['ædvәsәri]:n. 敌手, 对手 a. 敌手的, 敌对的 
228.fully['fuli]:adv. 十分地, 完全地, 充分地 
=======
>>>>>>> 50f1fbac684ef65c788c2c3b1cb359dd2a904378
